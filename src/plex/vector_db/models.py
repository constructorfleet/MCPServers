# generated by datamodel-codegen:
#   filename:  openapi.json
#   timestamp: 2025-08-07T03:36:14+00:00

from __future__ import annotations

from datetime import datetime
from enum import Enum
from typing import Annotated, Any, Dict, List, Optional, Set, TypeVar, Union
from uuid import UUID

from pydantic import AfterValidator, AnyUrl, BaseModel, Extra, Field

from plex.utils.mixins import ClientMixin, get, put, post

T = TypeVar('T')
def assert_unique_list(x: List[T]) -> bool:
    if len(set(x)) != len(x):
        raise ValueError('List items are not unique')
    return True

UniqueList = Annotated[List[T], AfterValidator(assert_unique_list)]

class Status(BaseModel):
    error: Optional[str] = Field(None, description='Description of the occurred error.')


class ErrorResponse(BaseModel):
    time: Optional[float] = Field(None, description='Time spent to process this request')
    status: Optional[Status] = None
    result: Optional[Dict[str, Any]] = None

class OperationResponse(BaseModel):
    result: bool
    status: Optional[Status] = None
    time: Optional[float] = Field(None, description='Time spent to process this request')

class CollectionDescription(BaseModel):
    name: str


class CollectionStatus(Enum):
    GREEN = 'green'
    YELLOW = 'yellow'
    RED = 'red'


class OptimizersStatus1(Enum):
    OK = 'ok'


class OptimizersStatus2(BaseModel):
    class Config:
        extra = Extra.forbid

    error: str


class OptimizersStatus(BaseModel):
    __root__: Union[OptimizersStatus1, OptimizersStatus2] = Field(
        ..., description='Current state of the collection'
    )


class Distance(Enum):
    COSINE = 'Cosine'
    EUCLID = 'Euclid'
    DOT = 'Dot'


class HnswConfig(BaseModel):
    m: int = Field(
        ...,
        description='Number of edges per node in the index graph. Larger the value - more accurate the search, more space required.',
        ge=0,
    )
    ef_construct: int = Field(
        ...,
        description='Number of neighbours to consider during the index building. Larger the value - more accurate the search, more time required to build index.',
        ge=0,
    )
    full_scan_threshold: int = Field(
        ...,
        description="Minimal size (in KiloBytes) of vectors for additional payload-based indexing. If payload chunk is smaller than `full_scan_threshold_kb` additional indexing won't be used - in this case full-scan search should be preferred by query planner and additional indexing is not required. Note: 1Kb = 1 vector of size 256",
        ge=0,
    )
    max_indexing_threads: Optional[int] = Field(
        0,
        description='Number of parallel threads used for background index building. If 0 - auto selection.',
        ge=0,
    )
    on_disk: Optional[bool] = Field(
        None,
        description='Store HNSW index on disk. If set to false, index will be stored in RAM. Default: false',
    )
    payload_m: Optional[int] = Field(
        None,
        description='Custom M param for hnsw graph built for payload index. If not set, default M will be used.',
        ge=0,
    )


class OptimizersConfig(BaseModel):
    deleted_threshold: float = Field(
        ...,
        description='The minimal fraction of deleted vectors in a segment, required to perform segment optimization',
    )
    vacuum_min_vector_number: int = Field(
        ...,
        description='The minimal number of vectors in a segment, required to perform segment optimization',
        ge=0,
    )
    default_segment_number: int = Field(
        ...,
        description='Target amount of segments optimizer will try to keep. Real amount of segments may vary depending on multiple parameters: - Amount of stored points - Current write RPS\n\nIt is recommended to select default number of segments as a factor of the number of search threads, so that each segment would be handled evenly by one of the threads If `default_segment_number = 0`, will be automatically selected by the number of available CPUs',
        ge=0,
    )
    max_segment_size: Optional[int] = Field(
        None,
        description='Do not create segments larger this size (in KiloBytes). Large segments might require disproportionately long indexation times, therefore it makes sense to limit the size of segments.\n\nIf indexation speed have more priority for your - make this parameter lower. If search speed is more important - make this parameter higher. Note: 1Kb = 1 vector of size 256 If not set, will be automatically selected considering the number of available CPUs.',
        ge=0,
    )
    memmap_threshold: Optional[int] = Field(
        None,
        description='Maximum size (in KiloBytes) of vectors to store in-memory per segment. Segments larger than this threshold will be stored as read-only memmaped file. To enable memmap storage, lower the threshold Note: 1Kb = 1 vector of size 256 If not set, mmap will not be used.',
        ge=0,
    )
    indexing_threshold: int = Field(
        ...,
        description='Maximum size (in KiloBytes) of vectors allowed for plain index. Default value based on <https://github.com/google-research/google-research/blob/master/scann/docs/algorithms.md> Note: 1Kb = 1 vector of size 256',
        ge=0,
    )
    flush_interval_sec: int = Field(
        ..., description='Minimum interval between forced flushes.', ge=0
    )
    max_optimization_threads: int = Field(
        ..., description='Maximum available threads for optimization workers', ge=0
    )


class WalConfig(BaseModel):
    wal_capacity_mb: int = Field(..., description='Size of a single WAL segment in MB', ge=0)
    wal_segments_ahead: int = Field(
        ..., description='Number of WAL segments to create ahead of actually used ones', ge=0
    )


class PayloadSchemaType(Enum):
    KEYWORD = 'keyword'
    INTEGER = 'integer'
    FLOAT = 'float'
    GEO = 'geo'
    TEXT = 'text'


class TextIndexType(Enum):
    TEXT = 'text'


class TokenizerType(Enum):
    PREFIX = 'prefix'
    WHITESPACE = 'whitespace'
    WORD = 'word'


class ExtendedPointId1(BaseModel):
    __root__: int = Field(
        ..., description='Type, used for specifying point ID in user interface', ge=0
    )


class ExtendedPointId(BaseModel):
    __root__: Union[ExtendedPointId1, UUID] = Field(
        ..., description='Type, used for specifying point ID in user interface'
    )


class PayloadSelectorInclude(BaseModel):
    class Config:
        extra = Extra.forbid

    include: List[str] = Field(..., description='Only include this payload keys')


class PayloadSelectorExclude(BaseModel):
    class Config:
        extra = Extra.forbid

    exclude: List[str] = Field(..., description='Exclude this fields from returning payload')


class WithVector(BaseModel):
    __root__: Union[bool, List[str]] = Field(
        ..., description='Options for specifying which vector to include'
    )


class Payload(BaseModel):
    pass

    class Config:
        extra = Extra.allow


class VectorStruct(BaseModel):
    __root__: Union[List[float], Dict[str, List[float]]] = Field(
        ...,
        description='Full vector data per point separator with single and multiple vector modes',
    )


class NamedVector(BaseModel):
    name: str = Field(..., description='Name of vector data')
    vector: List[float] = Field(..., description='Vector data')


class ValueVariants(BaseModel):
    __root__: Union[str, int, bool]


class MatchText(BaseModel):
    text: str


class Range(BaseModel):
    lt: Optional[float] = Field(None, description='point.key < range.lt')
    gt: Optional[float] = Field(None, description='point.key > range.gt')
    gte: Optional[float] = Field(None, description='point.key >= range.gte')
    lte: Optional[float] = Field(None, description='point.key <= range.lte')


class GeoPoint(BaseModel):
    lon: float
    lat: float


class GeoRadius(BaseModel):
    center: GeoPoint
    radius: float = Field(..., description='Radius of the area in meters')


class ValuesCount(BaseModel):
    lt: Optional[int] = Field(None, description='point.key.length() < values_count.lt', ge=0)
    gt: Optional[int] = Field(None, description='point.key.length() > values_count.gt', ge=0)
    gte: Optional[int] = Field(None, description='point.key.length() >= values_count.gte', ge=0)
    lte: Optional[int] = Field(None, description='point.key.length() <= values_count.lte', ge=0)


class PayloadField(BaseModel):
    key: str = Field(..., description='Payload field name')


class HasIdCondition(BaseModel):
    has_id: Set[ExtendedPointId] = Field(..., description='List of point IDs to match')


class SearchParams(BaseModel):
    hnsw_ef: Optional[int] = Field(
        None,
        description='Params relevant to HNSW index /// Size of the beam in a beam-search. Larger the value - more accurate the result, more time required for search.',
        ge=0,
    )
    exact: Optional[bool] = Field(
        False,
        description='Search without approximation. If set to true, search may run long but with exact results.',
    )


class ScoredPoint(BaseModel):
    id: ExtendedPointId
    version: int = Field(..., description='Point version', ge=0)
    score: float = Field(..., description='Points vector distance to the query vector')
    payload: Optional[Union[Payload, Any]] = Field(
        None, description='Payload - values assigned to the point'
    )
    vector: Optional[Union[VectorStruct, Any]] = Field(None, description='Vector of the point')


class UpdateStatus(Enum):
    ACKNOWLEDGED = 'acknowledged'
    COMPLETED = 'completed'


class UsingVector(BaseModel):
    __root__: str


class LookupLocation(BaseModel):
    collection: str = Field(..., description='Name of the collection used for lookup')
    vector: Optional[str] = Field(
        None,
        description='Optional name of the vector field within the collection. If not provided, the default vector field will be used.',
    )


class HnswConfigDiff(BaseModel):
    m: Optional[int] = Field(
        None,
        description='Number of edges per node in the index graph. Larger the value - more accurate the search, more space required.',
        ge=0,
    )
    ef_construct: Optional[int] = Field(
        None,
        description='Number of neighbours to consider during the index building. Larger the value - more accurate the search, more time required to build index.',
        ge=0,
    )
    full_scan_threshold: Optional[int] = Field(
        None,
        description="Minimal size (in KiloBytes) of vectors for additional payload-based indexing. If payload chunk is smaller than `full_scan_threshold_kb` additional indexing won't be used - in this case full-scan search should be preferred by query planner and additional indexing is not required. Note: 1Kb = 1 vector of size 256",
        ge=0,
    )
    max_indexing_threads: Optional[int] = Field(
        None,
        description='Number of parallel threads used for background index building. If 0 - auto selection.',
        ge=0,
    )
    on_disk: Optional[bool] = Field(
        None,
        description='Store HNSW index on disk. If set to false, index will be stored in RAM. Default: false',
    )
    payload_m: Optional[int] = Field(
        None,
        description='Custom M param for additional payload-aware HNSW links. If not set, default M will be used.',
        ge=0,
    )


class WalConfigDiff(BaseModel):
    wal_capacity_mb: Optional[int] = Field(
        None, description='Size of a single WAL segment in MB', ge=0
    )
    wal_segments_ahead: Optional[int] = Field(
        None, description='Number of WAL segments to create ahead of actually used ones', ge=0
    )


class OptimizersConfigDiff(BaseModel):
    deleted_threshold: Optional[float] = Field(
        None,
        description='The minimal fraction of deleted vectors in a segment, required to perform segment optimization',
    )
    vacuum_min_vector_number: Optional[int] = Field(
        None,
        description='The minimal number of vectors in a segment, required to perform segment optimization',
        ge=0,
    )
    default_segment_number: Optional[int] = Field(
        None,
        description='Target amount of segments optimizer will try to keep. Real amount of segments may vary depending on multiple parameters: - Amount of stored points - Current write RPS\n\nIt is recommended to select default number of segments as a factor of the number of search threads, so that each segment would be handled evenly by one of the threads If `default_segment_number = 0`, will be automatically selected by the number of available CPUs',
        ge=0,
    )
    max_segment_size: Optional[int] = Field(
        None,
        description='Do not create segments larger this size (in KiloBytes). Large segments might require disproportionately long indexation times, therefore it makes sense to limit the size of segments.\n\nIf indexation speed have more priority for your - make this parameter lower. If search speed is more important - make this parameter higher. Note: 1Kb = 1 vector of size 256',
        ge=0,
    )
    memmap_threshold: Optional[int] = Field(
        None,
        description='Maximum size (in KiloBytes) of vectors to store in-memory per segment. Segments larger than this threshold will be stored as read-only memmaped file. To enable memmap storage, lower the threshold Note: 1Kb = 1 vector of size 256',
        ge=0,
    )
    indexing_threshold: Optional[int] = Field(
        None,
        description='Maximum size (in KiloBytes) of vectors allowed for plain index. Default value based on <https://github.com/google-research/google-research/blob/master/scann/docs/algorithms.md> Note: 1Kb = 1 vector of size 256',
        ge=0,
    )
    flush_interval_sec: Optional[int] = Field(
        None, description='Minimum interval between forced flushes.', ge=0
    )
    max_optimization_threads: Optional[int] = Field(
        None, description='Maximum available threads for optimization workers', ge=0
    )


class CollectionParamsDiff(BaseModel):
    replication_factor: Optional[int] = Field(
        None, description='Number of replicas for each shard', ge=1
    )
    write_consistency_factor: Optional[int] = Field(
        None,
        description='Minimal number successful responses from replicas to consider operation successful',
        ge=1,
    )


class CreateAlias(BaseModel):
    collection_name: str
    alias_name: str


class DeleteAlias(BaseModel):
    alias_name: str


class RenameAlias(BaseModel):
    old_alias_name: str
    new_alias_name: str


class PointIdsList(BaseModel):
    points: List[ExtendedPointId]


class BatchVectorStruct(BaseModel):
    __root__: Union[List[List[float]], Dict[str, List[List[float]]]]


class PointStruct(BaseModel):
    id: ExtendedPointId
    vector: VectorStruct
    payload: Optional[Union[Payload, Any]] = Field(None, description='Payload values (optional)')


class Batch(BaseModel):
    ids: List[ExtendedPointId]
    vectors: BatchVectorStruct
    payloads: Optional[List[Union[Payload, Any]]] = None


class PointsBatch(BaseModel):
    batch: Batch


class PointsList(BaseModel):
    points: List[PointStruct]


class Status1(Enum):
    DISABLED = 'disabled'


class ClusterStatus1(BaseModel):
    status: Status1


class Status2(Enum):
    ENABLED = 'enabled'


class PeerInfo(BaseModel):
    uri: str


class StateRole(Enum):
    FOLLOWER = 'Follower'
    CANDIDATE = 'Candidate'
    LEADER = 'Leader'
    PRE_CANDIDATE = 'PreCandidate'


class ConsensusThreadStatus2(Enum):
    WORKING = 'working'


class ConsensusThreadStatus1(BaseModel):
    consensus_thread_status: ConsensusThreadStatus2
    last_update: datetime


class ConsensusThreadStatus4(Enum):
    STOPPED = 'stopped'


class ConsensusThreadStatus3(BaseModel):
    consensus_thread_status: ConsensusThreadStatus4


class ConsensusThreadStatus6(Enum):
    STOPPED_WITH_ERR = 'stopped_with_err'


class ConsensusThreadStatus5(BaseModel):
    consensus_thread_status: ConsensusThreadStatus6
    err: str


class ConsensusThreadStatus(BaseModel):
    __root__: Union[ConsensusThreadStatus1, ConsensusThreadStatus3, ConsensusThreadStatus5] = Field(
        ..., description='Information about current consensus thread status'
    )


class MessageSendErrors(BaseModel):
    count: int = Field(..., ge=0)
    latest_error: Optional[str] = None


class SnapshotDescription(BaseModel):
    name: str
    creation_time: Optional[str] = None
    size: int = Field(..., ge=0)


class CountResult(BaseModel):
    count: int = Field(..., description='Number of points which satisfy the conditions', ge=0)


class ReplicaState(Enum):
    ACTIVE = 'Active'
    DEAD = 'Dead'
    PARTIAL = 'Partial'


class RemoteShardInfo(BaseModel):
    shard_id: int = Field(..., description='Remote shard id', ge=0)
    peer_id: int = Field(..., description='Remote peer id', ge=0)
    state: ReplicaState


class ShardTransferInfo(BaseModel):
    shard_id: int = Field(..., ge=0)
    from_: int = Field(..., alias='from', ge=0)
    to: int = Field(..., ge=0)
    sync: bool = Field(
        ...,
        description='If `true` transfer is a synchronization of a replicas If `false` transfer is a moving of a shard from one peer to another',
    )


class AppFeaturesTelemetry(BaseModel):
    debug: bool
    web_feature: bool
    service_debug_feature: bool


class RunningEnvironmentTelemetry(BaseModel):
    distribution: Optional[str] = None
    distribution_version: Optional[str] = None
    is_docker: bool
    cores: Optional[int] = Field(None, ge=0)
    ram_size: Optional[int] = Field(None, ge=0)
    disk_size: Optional[int] = Field(None, ge=0)
    cpu_flags: str


class SegmentType(Enum):
    PLAIN = 'plain'
    INDEXED = 'indexed'
    SPECIAL = 'special'


class VectorDataConfig(BaseModel):
    size: int = Field(..., description='Size of a vectors used', ge=0)
    distance: Distance


class Type(Enum):
    PLAIN = 'plain'


class Indexes1(BaseModel):
    type: Type
    options: Dict[str, Any]


class Type1(Enum):
    HNSW = 'hnsw'


class Indexes2(BaseModel):
    type: Type1
    options: HnswConfig


class Indexes(BaseModel):
    __root__: Union[Indexes1, Indexes2] = Field(
        ..., description='Vector index configuration of the segment'
    )


class Type2(Enum):
    IN_MEMORY = 'in_memory'


class StorageType1(BaseModel):
    type: Type2


class Type3(Enum):
    MMAP = 'mmap'


class StorageType2(BaseModel):
    type: Type3


class StorageType(BaseModel):
    __root__: Union[StorageType1, StorageType2] = Field(..., description='Type of vector storage')


class Type4(Enum):
    IN_MEMORY = 'in_memory'


class PayloadStorageType1(BaseModel):
    type: Type4


class Type5(Enum):
    ON_DISK = 'on_disk'


class PayloadStorageType2(BaseModel):
    type: Type5


class PayloadStorageType(BaseModel):
    __root__: Union[PayloadStorageType1, PayloadStorageType2] = Field(
        ..., description='Type of payload storage'
    )


class OperationDurationStatistics(BaseModel):
    count: int = Field(..., ge=0)
    fail_count: Optional[int] = Field(None, ge=0)
    avg_duration_micros: Optional[float] = None
    min_duration_micros: Optional[float] = None
    max_duration_micros: Optional[float] = None


class PayloadIndexTelemetry(BaseModel):
    field_name: Optional[str] = None
    points_values_count: int = Field(..., ge=0)
    points_count: int = Field(..., ge=0)
    histogram_bucket_size: Optional[int] = Field(None, ge=0)


class OptimizerTelemetry(BaseModel):
    status: OptimizersStatus
    optimizations: OperationDurationStatistics


class RemoteShardTelemetry(BaseModel):
    shard_id: int = Field(..., ge=0)
    peer_id: Optional[int] = Field(None, ge=0)
    searches: OperationDurationStatistics
    updates: OperationDurationStatistics


class ClusterStatusTelemetry(BaseModel):
    number_of_peers: int = Field(..., ge=0)
    term: int = Field(..., ge=0)
    commit: int = Field(..., ge=0)
    pending_operations: int = Field(..., ge=0)
    role: Optional[Union[StateRole, Any]] = None
    is_voter: bool
    peer_id: Optional[int] = Field(None, ge=0)
    consensus_thread_status: ConsensusThreadStatus


class P2pConfigTelemetry(BaseModel):
    connection_pool_size: int = Field(..., ge=0)


class ConsensusConfigTelemetry(BaseModel):
    max_message_queue_size: int = Field(..., ge=0)
    tick_period_ms: int = Field(..., ge=0)
    bootstrap_timeout_sec: int = Field(..., ge=0)


class WebApiTelemetry(BaseModel):
    responses: Dict[str, Dict[str, OperationDurationStatistics]]


class GrpcTelemetry(BaseModel):
    responses: Dict[str, OperationDurationStatistics]


class MoveShard(BaseModel):
    shard_id: int = Field(..., ge=0)
    to_peer_id: int = Field(..., ge=0)
    from_peer_id: int = Field(..., ge=0)


class ReplicateShardOperation(BaseModel):
    replicate_shard: MoveShard


class AbortTransferOperation(BaseModel):
    abort_transfer: MoveShard


class Replica(BaseModel):
    shard_id: int = Field(..., ge=0)
    peer_id: int = Field(..., ge=0)


class LocksOption(BaseModel):
    error_message: Optional[str] = None
    write: bool


class SnapshotPriority(Enum):
    SNAPSHOT = 'snapshot'
    REPLICA = 'replica'


class CollectionsResponse(BaseModel):
    collections: List[CollectionDescription]

class VectorParams(BaseModel):
    size: int = Field(..., description='Size of a vectors used', ge=1)
    distance: Distance


class TextIndexParams(BaseModel):
    type: TextIndexType
    tokenizer: Optional[TokenizerType] = None
    min_token_len: Optional[int] = Field(None, ge=0)
    max_token_len: Optional[int] = Field(None, ge=0)
    lowercase: Optional[bool] = Field(
        None, description='If true, lowercase all tokens. Default: true'
    )


class PayloadSelector(BaseModel):
    __root__: Union[PayloadSelectorInclude, PayloadSelectorExclude] = Field(
        ..., description='Specifies how to treat payload selector'
    )


class Record(BaseModel):
    id: ExtendedPointId
    payload: Optional[Union[Payload, Any]] = Field(
        None, description='Payload - values assigned to the point'
    )
    vector: Optional[Union[VectorStruct, Any]] = Field(None, description='Vector of the point')


class NamedVectorStruct(BaseModel):
    __root__: Union[List[float], NamedVector] = Field(
        ...,
        description='Vector data separator for named and unnamed modes Unanmed mode:\n\n{ "vector": [1.0, 2.0, 3.0] }\n\nor named mode:\n\n{ "vector": { "vector": [1.0, 2.0, 3.0], "name": "image-embeddings" } }',
    )


class MatchValue(BaseModel):
    value: ValueVariants


class GeoBoundingBox(BaseModel):
    top_left: GeoPoint
    bottom_right: GeoPoint


class IsEmptyCondition(BaseModel):
    is_empty: PayloadField


class UpdateResult(BaseModel):
    operation_id: int = Field(..., description='Sequential number of the operation', ge=0)
    status: UpdateStatus


class ScrollResult(BaseModel):
    points: List[Record] = Field(..., description='List of retrieved points')
    next_page_offset: Optional[Union[ExtendedPointId, Any]] = Field(
        None, description='Offset which should be used to retrieve a next page result'
    )


@post('/collections/{collection_name}/update', OperationResponse)
class UpdateCollection(ClientMixin):
    optimizers_config: Optional[Union[OptimizersConfigDiff, Any]] = Field(
        None,
        description='Custom params for Optimizers.  If none - values from service configuration file are used. This operation is blocking, it will only proceed ones all current optimizations are complete',
    )
    params: Optional[Union[CollectionParamsDiff, Any]] = Field(
        None,
        description='Collection base params.  If none - values from service configuration file are used.',
    )


class CreateAliasOperation(BaseModel):
    create_alias: CreateAlias


class DeleteAliasOperation(BaseModel):
    delete_alias: DeleteAlias


class RenameAliasOperation(BaseModel):
    rename_alias: RenameAlias


class PointInsertOperations(BaseModel):
    __root__: Union[PointsBatch, PointsList]


class RaftInfo(BaseModel):
    term: int = Field(
        ...,
        description='Raft divides time into terms of arbitrary length, each beginning with an election. If a candidate wins the election, it remains the leader for the rest of the term. The term number increases monotonically. Each server stores the current term number which is also exchanged in every communication.',
        ge=0,
    )
    commit: int = Field(
        ...,
        description='The index of the latest committed (finalized) operation that this peer is aware of.',
        ge=0,
    )
    pending_operations: int = Field(
        ..., description='Number of consensus operations pending to be applied on this peer', ge=0
    )
    leader: Optional[int] = Field(None, description='Leader of the current term', ge=0)
    role: Optional[Union[StateRole, Any]] = Field(
        None, description='Role of this peer in the current term'
    )
    is_voter: bool = Field(..., description='Is this peer a voter or a learner')


class LocalShardInfo(BaseModel):
    shard_id: int = Field(..., description='Local shard id', ge=0)
    points_count: int = Field(..., description='Number of points in the shard', ge=0)
    state: ReplicaState


class AppBuildTelemetry(BaseModel):
    version: str
    features: Optional[Union[AppFeaturesTelemetry, Any]] = None
    system: Optional[Union[RunningEnvironmentTelemetry, Any]] = None


class SegmentConfig(BaseModel):
    vector_data: Dict[str, VectorDataConfig]
    index: Indexes
    storage_type: StorageType
    payload_storage_type: Optional[PayloadStorageType] = None


class VectorIndexSearchesTelemetry(BaseModel):
    index_name: Optional[str] = None
    unfiltered_plain: OperationDurationStatistics
    unfiltered_hnsw: OperationDurationStatistics
    filtered_plain: OperationDurationStatistics
    filtered_small_cardinality: OperationDurationStatistics
    filtered_large_cardinality: OperationDurationStatistics
    filtered_exact: OperationDurationStatistics
    unfiltered_exact: OperationDurationStatistics


class ClusterConfigTelemetry(BaseModel):
    grpc_timeout_ms: int = Field(..., ge=0)
    p2p: P2pConfigTelemetry
    consensus: ConsensusConfigTelemetry


class RequestsTelemetry(BaseModel):
    rest: WebApiTelemetry
    grpc: GrpcTelemetry


class MoveShardOperation(BaseModel):
    move_shard: MoveShard


class DropReplicaOperation(BaseModel):
    drop_replica: Replica


class SnapshotRecover(BaseModel):
    location: AnyUrl = Field(
        ...,
        description='Examples: - URL `http://localhost:8080/collections/my_collection/snapshots/my_snapshot` - Local path `file:///qdrant/snapshots/test_collection-2022-08-04-10-49-10.snapshot`',
    )
    priority: Optional[SnapshotPriority] = None


class VectorsConfig(BaseModel):
    __root__: Union[VectorParams, Dict[str, VectorParams]] = Field(
        ...,
        description='Vector params separator for single and multiple vector modes Single mode:\n\n{ "size": 128, "distance": "Cosine" }\n\nor multiple mode:\n\n{ "default": { "size": 128, "distance": "Cosine" } }',
    )


class PayloadSchemaParams(BaseModel):
    __root__: TextIndexParams = Field(..., description='Payload type with parameters')


class WithPayloadInterface(BaseModel):
    __root__: Union[bool, List[str], PayloadSelector] = Field(
        ..., description='Options for specifying which payload to include or not'
    )


class Match(BaseModel):
    __root__: Union[MatchValue, MatchText] = Field(..., description='Match filter request')

@put('/collections/{collection_name}', OperationResponse)
class CreateCollection(ClientMixin):
    vectors: VectorsConfig
    shard_number: Optional[int] = Field(
        None,
        description='Number of shards in collection. Default is 1 for standalone, otherwise equal to the number of nodes Minimum is 1',
        ge=0,
    )
    replication_factor: Optional[int] = Field(
        None, description='Number of shards replicas. Default is 1 Minimum is 1', ge=0
    )
    write_consistency_factor: Optional[int] = Field(
        None,
        description='Defines how many replicas should apply the operation for us to consider it successful. Increasing this number will make the collection more resilient to inconsistencies, but will also make it fail if not enough replicas are available. Does not have any performance impact.',
        ge=0,
    )
    on_disk_payload: Optional[bool] = Field(
        None,
        description="If true - point's payload will not be stored in memory. It will be read from the disk every time it is requested. This setting saves RAM by (slightly) increasing the response time. Note: those payload values that are involved in filtering and are indexed - remain in RAM.",
    )
    hnsw_config: Optional[Union[HnswConfigDiff, Any]] = Field(
        None,
        description='Custom params for HNSW index. If none - values from service configuration file are used.',
    )
    wal_config: Optional[Union[WalConfigDiff, Any]] = Field(
        None,
        description='Custom params for WAL. If none - values from service configuration file are used.',
    )
    optimizers_config: Optional[Union[OptimizersConfigDiff, Any]] = Field(
        None,
        description='Custom params for Optimizers.  If none - values from service configuration file are used.',
    )


class AliasOperations(BaseModel):
    __root__: Union[CreateAliasOperation, DeleteAliasOperation, RenameAliasOperation] = Field(
        ..., description='Group of all the possible operations related to collection aliases'
    )


class PayloadFieldSchema(BaseModel):
    __root__: Union[PayloadSchemaType, PayloadSchemaParams]


class ClusterStatus2(BaseModel):
    status: Status2
    peer_id: int = Field(..., description='ID of this peer', ge=0)
    peers: Dict[str, PeerInfo] = Field(
        ..., description='Peers composition of the cluster with main information'
    )
    raft_info: RaftInfo
    consensus_thread_status: ConsensusThreadStatus
    message_send_failures: Dict[str, MessageSendErrors] = Field(
        ...,
        description='Consequent failures of message send operations in consensus by peer address. On the first success to send to that peer - entry is removed from this hashmap.',
    )


class ClusterStatus(BaseModel):
    __root__: Union[ClusterStatus1, ClusterStatus2] = Field(
        ..., description='Information about current cluster status and structure'
    )


class CollectionClusterInfo(BaseModel):
    peer_id: int = Field(..., description='ID of this peer', ge=0)
    shard_count: int = Field(..., description='Total number of shards', ge=0)
    local_shards: List[LocalShardInfo] = Field(..., description='Local shards')
    remote_shards: List[RemoteShardInfo] = Field(..., description='Remote shards')
    shard_transfers: List[ShardTransferInfo] = Field(..., description='Shard transfers')


class ClusterTelemetry(BaseModel):
    enabled: bool
    status: Optional[Union[ClusterStatusTelemetry, Any]] = None
    config: Optional[Union[ClusterConfigTelemetry, Any]] = None


class ClusterOperations(BaseModel):
    __root__: Union[
        MoveShardOperation, ReplicateShardOperation, AbortTransferOperation, DropReplicaOperation
    ]


class CollectionParams(BaseModel):
    vectors: VectorsConfig
    shard_number: Optional[int] = Field(1, description='Number of shards the collection has', ge=1)
    replication_factor: Optional[int] = Field(
        1, description='Number of replicas for each shard', ge=1
    )
    write_consistency_factor: Optional[int] = Field(
        1,
        description='Defines how many replicas should apply the operation for us to consider it successful. Increasing this number will make the collection more resilient to inconsistencies, but will also make it fail if not enough replicas are available. Does not have any performance impact.',
        ge=1,
    )
    on_disk_payload: Optional[bool] = Field(
        False,
        description="If true - point's payload will not be stored in memory. It will be read from the disk every time it is requested. This setting saves RAM by (slightly) increasing the response time. Note: those payload values that are involved in filtering and are indexed - remain in RAM.",
    )


class PayloadIndexInfo(BaseModel):
    data_type: PayloadSchemaType
    params: Optional[Union[PayloadSchemaParams, Any]] = None
    points: int = Field(..., description='Number of points indexed with this index', ge=0)


class PointRequest(BaseModel):
    ids: List[ExtendedPointId] = Field(..., description='Look for points with ids')
    with_payload: Optional[Union[WithPayloadInterface, Any]] = Field(
        None, description='Select which payload to return with the response. Default: All'
    )
    with_vector: Optional[WithVector] = None


class FieldCondition(BaseModel):
    key: str = Field(..., description='Payload key')
    match: Optional[Union[Match, Any]] = Field(
        None, description='Check if point has field with a given value'
    )
    range: Optional[Union[Range, Any]] = Field(
        None, description='Check if points value lies in a given range'
    )
    geo_bounding_box: Optional[Union[GeoBoundingBox, Any]] = Field(
        None, description='Check if points geo location lies in a given area'
    )
    geo_radius: Optional[Union[GeoRadius, Any]] = Field(
        None, description='Check if geo point is within a given radius'
    )
    values_count: Optional[Union[ValuesCount, Any]] = Field(
        None, description='Check number of values of the field'
    )


class ChangeAliasesOperation(BaseModel):
    actions: List[AliasOperations]


class CreateFieldIndex(BaseModel):
    field_name: str
    field_schema: Optional[Union[PayloadFieldSchema, Any]] = None


class SegmentInfo(BaseModel):
    segment_type: SegmentType
    num_vectors: int = Field(..., ge=0)
    num_points: int = Field(..., ge=0)
    num_deleted_vectors: int = Field(..., ge=0)
    ram_usage_bytes: int = Field(..., ge=0)
    disk_usage_bytes: int = Field(..., ge=0)
    is_appendable: bool
    index_schema: Dict[str, PayloadIndexInfo]


class CollectionsAggregatedTelemetry(BaseModel):
    vectors: int = Field(..., ge=0)
    optimizers_status: OptimizersStatus
    params: CollectionParams


class CollectionConfig(BaseModel):
    params: CollectionParams
    hnsw_config: HnswConfig
    optimizer_config: OptimizersConfig
    wal_config: WalConfig


class SegmentTelemetry(BaseModel):
    info: SegmentInfo
    config: SegmentConfig
    vector_index_searches: List[VectorIndexSearchesTelemetry]
    payload_field_indices: List[PayloadIndexTelemetry]


class CollectionInfo(BaseModel):
    status: CollectionStatus
    optimizer_status: OptimizersStatus
    vectors_count: int = Field(
        ...,
        description='Number of vectors in collection All vectors in collection are available for querying Calculated as `points_count x vectors_per_point` Where `vectors_per_point` is a number of named vectors in schema',
        ge=0,
    )
    indexed_vectors_count: int = Field(
        ...,
        description='Number of indexed vectors in the collection. Indexed vectors in large segments are faster to query, as it is stored in vector index (HNSW)',
        ge=0,
    )
    points_count: int = Field(
        ...,
        description='Number of points (vectors + payloads) in collection Each point could be accessed by unique id',
        ge=0,
    )
    segments_count: int = Field(
        ...,
        description='Number of segments in collection. Each segment has independent vector as payload indexes',
        ge=0,
    )
    config: CollectionConfig
    payload_schema: Dict[str, PayloadIndexInfo] = Field(..., description='Types of stored payload')

@get("/collections", CollectionsResponse)
class ListCollections(ClientMixin):
    pass

@get("/collections/{collection_name}", CollectionInfo)
class GetCollection(ClientMixin):
    collection_name: str

class LocalShardTelemetry(BaseModel):
    variant_name: Optional[str] = None
    segments: List[SegmentTelemetry]
    optimizations: OptimizerTelemetry


class ReplicaSetTelemetry(BaseModel):
    id: int = Field(..., ge=0)
    local: Optional[Union[LocalShardTelemetry, Any]] = None
    remote: List[RemoteShardTelemetry]
    replicate_states: Dict[str, ReplicaState]


class CollectionTelemetry(BaseModel):
    id: str
    init_time_ms: int = Field(..., ge=0)
    config: CollectionConfig
    shards: List[ReplicaSetTelemetry]
    transfers: List[ShardTransferInfo]


class CollectionTelemetryEnum(BaseModel):
    __root__: Union[CollectionTelemetry, CollectionsAggregatedTelemetry]


class CollectionsTelemetry(BaseModel):
    number_of_collections: int = Field(..., ge=0)
    collections: Optional[List[CollectionTelemetryEnum]] = None


class TelemetryData(BaseModel):
    id: str
    app: AppBuildTelemetry
    collections: CollectionsTelemetry
    cluster: ClusterTelemetry
    requests: RequestsTelemetry


class SearchRequest(BaseModel):
    vector: NamedVectorStruct
    filter: Optional[Union[Filter, Any]] = Field(
        None, description='Look only for points which satisfies this conditions'
    )
    params: Optional[Union[SearchParams, Any]] = Field(None, description='Additional search params')
    limit: int = Field(..., description='Max number of result to return', ge=0)
    offset: Optional[int] = Field(
        0,
        description='Offset of the first result to return. May be used to paginate results. Note: large offset values may cause performance issues.',
        ge=0,
    )
    with_payload: Optional[Union[WithPayloadInterface, Any]] = Field(
        None, description='Select which payload to return with the response. Default: None'
    )
    with_vector: Optional[Union[WithVector, Any]] = Field(
        None, description='Whether to return the point vector with the result?'
    )
    score_threshold: Optional[float] = Field(
        None,
        description='Define a minimal score threshold for the result. If defined, less similar results will not be returned. Score of the returned result might be higher or smaller than the threshold depending on the Distance function used. E.g. for cosine similarity only higher scores will be returned.',
    )


class Filter(BaseModel):
    class Config:
        extra = Extra.forbid

    should: Optional[List[Condition]] = Field(
        None, description='At least one of those conditions should match'
    )
    must: Optional[List[Condition]] = Field(None, description='All conditions must match')
    must_not: Optional[List[Condition]] = Field(None, description='All conditions must NOT match')


class Condition(BaseModel):
    __root__: Union[FieldCondition, IsEmptyCondition, HasIdCondition, Filter]


class RecommendRequest(BaseModel):
    positive: List[ExtendedPointId] = Field(..., description='Look for vectors closest to those')
    negative: Optional[List[ExtendedPointId]] = Field(
        [], description='Try to avoid vectors like this'
    )
    filter: Optional[Union[Filter, Any]] = Field(
        None, description='Look only for points which satisfies this conditions'
    )
    params: Optional[Union[SearchParams, Any]] = Field(None, description='Additional search params')
    limit: int = Field(..., description='Max number of result to return', ge=0)
    offset: Optional[int] = Field(
        0,
        description='Offset of the first result to return. May be used to paginate results. Note: large offset values may cause performance issues.',
        ge=0,
    )
    with_payload: Optional[Union[WithPayloadInterface, Any]] = Field(
        None, description='Select which payload to return with the response. Default: None'
    )
    with_vector: Optional[Union[WithVector, Any]] = Field(
        None, description='Whether to return the point vector with the result?'
    )
    score_threshold: Optional[float] = Field(
        None,
        description='Define a minimal score threshold for the result. If defined, less similar results will not be returned. Score of the returned result might be higher or smaller than the threshold depending on the Distance function used. E.g. for cosine similarity only higher scores will be returned.',
    )
    using: Optional[Union[UsingVector, Any]] = Field(
        None,
        description='Define which vector to use for recommendation, if not specified - try to use default vector',
    )
    lookup_from: Optional[Union[LookupLocation, Any]] = Field(
        None,
        description='The location used to lookup vectors. If not specified - use current collection. Note: the other collection should have the same vector size as the current collection',
    )


class ScrollRequest(BaseModel):
    offset: Optional[Union[ExtendedPointId, Any]] = Field(
        None, description='Start ID to read points from.'
    )
    limit: Optional[int] = Field(None, description='Page size. Default: 10', ge=0)
    filter: Optional[Union[Filter, Any]] = Field(
        None,
        description='Look only for points which satisfies this conditions. If not provided - all points.',
    )
    with_payload: Optional[Union[WithPayloadInterface, Any]] = Field(
        None, description='Select which payload to return with the response. Default: All'
    )
    with_vector: Optional[WithVector] = None


class PointsSelector(BaseModel):
    __root__: Union[PointIdsList, FilterSelector]


class FilterSelector(BaseModel):
    filter: Filter


class SetPayload(BaseModel):
    payload: Payload
    points: Optional[List[ExtendedPointId]] = Field(
        None, description='Assigns payload to each point in this list'
    )
    filter: Optional[Union[Filter, Any]] = Field(
        None, description='Assigns payload to each point that satisfy this filter condition'
    )


class DeletePayload(BaseModel):
    keys: List[str] = Field(..., description='List of payload keys to remove from payload')
    points: Optional[List[ExtendedPointId]] = Field(
        None, description='Deletes values from each point in this list'
    )
    filter: Optional[Union[Filter, Any]] = Field(
        None, description='Deletes values from points that satisfy this filter condition'
    )


class CountRequest(BaseModel):
    filter: Optional[Union[Filter, Any]] = Field(
        None, description='Look only for points which satisfies this conditions'
    )
    exact: Optional[bool] = Field(
        True,
        description='If true, count exact number of points. If false, count approximate number of points faster. Approximate count might be unreliable during the indexing process. Default: true',
    )


class SearchRequestBatch(BaseModel):
    searches: List[SearchRequest]


class RecommendRequestBatch(BaseModel):
    searches: List[RecommendRequest]


SearchRequest.model_rebuild()
Filter.model_rebuild()
PointsSelector.model_rebuild()
